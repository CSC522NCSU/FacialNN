{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "mU54GOH6Lprg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iS_uFeHEhBd",
        "outputId": "faa44a97-9f77-4130-9c27-d83972c50676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FER-2013 downloaded to: /kaggle/input/fer2013\n",
            "✅ FER-2013 Loaded\n",
            "Classes: ['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "Train: (28709, 48, 48, 1), (28709, 7)\n",
            "Test: (7178, 48, 48, 1), (7178, 7)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import kagglehub\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Download FER-2013 dataset\n",
        "fer_path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "print(\"FER-2013 downloaded to:\", fer_path)\n",
        "\n",
        "# 2. Define image loader\n",
        "def load_images_from_dir(root_dir, target_size=(48, 48)):\n",
        "    X, y = [], []\n",
        "    for class_folder in os.listdir(root_dir):\n",
        "        class_path = os.path.join(root_dir, class_folder)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "        label = class_folder.lower()\n",
        "        for file in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, file)\n",
        "            try:\n",
        "                img = Image.open(img_path).convert(\"L\").resize(target_size)\n",
        "                X.append(np.array(img))\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {img_path}: {e}\")\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 3. Load training and testing sets\n",
        "train_dir = os.path.join(fer_path, \"train\")\n",
        "test_dir = os.path.join(fer_path, \"test\")\n",
        "\n",
        "X_train, y_train = load_images_from_dir(train_dir)\n",
        "X_test, y_test = load_images_from_dir(test_dir)\n",
        "\n",
        "# 4. Preprocess data (Standardize input features to [0,1])\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0\n",
        "X_train = np.expand_dims(X_train, -1)\n",
        "X_test = np.expand_dims(X_test, -1)\n",
        "\n",
        "# 5. Encode response class as one-hot labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = to_categorical(label_encoder.fit_transform(y_train))\n",
        "y_test = to_categorical(label_encoder.transform(y_test))\n",
        "\n",
        "# 6. Output summary\n",
        "print(\"✅ FER-2013 Loaded\")\n",
        "print(f\"Classes: {label_encoder.classes_}\")\n",
        "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Example (2 Dense Layer)"
      ],
      "metadata": {
        "id": "9V8qV0ieKwzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Flatten input shape from 48x48x1 to 2304\n",
        "input_shape = X_train.shape[1:]  # (48, 48, 1)\n",
        "flattened_input_dim = np.prod(input_shape)\n",
        "\n",
        "# Build the MLP (Feedforward Network)\n",
        "\n",
        "# Input shape - 2304\n",
        "# First layer - 512 Neurons\n",
        "# Second layer - 256 Neurons\n",
        "# Output layer - 7 Neurons (Softmax)\n",
        "\n",
        "# Relu activation after each hidden layer\n",
        "\n",
        "mlp_model = Sequential([\n",
        "    Flatten(input_shape=input_shape),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "mlp_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "mlp_model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Sl6OJAK4yW",
        "outputId": "6fe09c6d-ae0f-4030-8bad-f5ad6c3a975e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.2406 - loss: 1.9651 - val_accuracy: 0.3142 - val_loss: 1.7083\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3186 - loss: 1.7070 - val_accuracy: 0.3629 - val_loss: 1.6596\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3470 - loss: 1.6687 - val_accuracy: 0.3466 - val_loss: 1.6538\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3492 - loss: 1.6479 - val_accuracy: 0.3689 - val_loss: 1.6228\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3676 - loss: 1.6090 - val_accuracy: 0.3640 - val_loss: 1.6083\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3754 - loss: 1.5972 - val_accuracy: 0.3572 - val_loss: 1.6247\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3871 - loss: 1.5736 - val_accuracy: 0.3764 - val_loss: 1.5919\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3862 - loss: 1.5687 - val_accuracy: 0.3696 - val_loss: 1.6120\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3886 - loss: 1.5620 - val_accuracy: 0.3670 - val_loss: 1.5979\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4036 - loss: 1.5310 - val_accuracy: 0.3812 - val_loss: 1.5856\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3976 - loss: 1.5371 - val_accuracy: 0.3869 - val_loss: 1.5738\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3982 - loss: 1.5352 - val_accuracy: 0.3853 - val_loss: 1.5853\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4019 - loss: 1.5221 - val_accuracy: 0.3738 - val_loss: 1.5997\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4037 - loss: 1.5120 - val_accuracy: 0.3899 - val_loss: 1.5537\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4168 - loss: 1.4949 - val_accuracy: 0.3955 - val_loss: 1.5538\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4197 - loss: 1.4942 - val_accuracy: 0.3883 - val_loss: 1.5780\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4208 - loss: 1.4912 - val_accuracy: 0.3816 - val_loss: 1.5990\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4303 - loss: 1.4714 - val_accuracy: 0.3897 - val_loss: 1.5725\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4252 - loss: 1.4733 - val_accuracy: 0.3984 - val_loss: 1.5514\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4324 - loss: 1.4534 - val_accuracy: 0.3972 - val_loss: 1.5564\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4411 - loss: 1.4420 - val_accuracy: 0.4026 - val_loss: 1.5372\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4439 - loss: 1.4392 - val_accuracy: 0.4019 - val_loss: 1.5420\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4408 - loss: 1.4355 - val_accuracy: 0.3959 - val_loss: 1.5633\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4433 - loss: 1.4376 - val_accuracy: 0.3944 - val_loss: 1.5671\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4479 - loss: 1.4264 - val_accuracy: 0.3983 - val_loss: 1.5726\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4508 - loss: 1.4174 - val_accuracy: 0.3951 - val_loss: 1.5871\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4548 - loss: 1.4042 - val_accuracy: 0.3899 - val_loss: 1.5997\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4521 - loss: 1.4038 - val_accuracy: 0.4036 - val_loss: 1.5399\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4638 - loss: 1.3918 - val_accuracy: 0.4023 - val_loss: 1.5528\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4721 - loss: 1.3818 - val_accuracy: 0.3950 - val_loss: 1.5723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d0bb1886d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Architecture (Recurrent Layer into Dense Layer)\n",
        "\n"
      ],
      "metadata": {
        "id": "ksCsebVaLxHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.math import confusion_matrix\n",
        "\n",
        "# Reshape: (samples, 48 time steps, 48 features)\n",
        "X_train_rnn = X_train.reshape(-1, 48, 48)\n",
        "X_test_rnn = X_test.reshape(-1, 48, 48)\n",
        "\n",
        "# Build the RNN (Recurrent Neural Network)\n",
        "\n",
        "# We feed in each row of the data (48 pixels) into the recurrent layer, which\n",
        "# updates the hidden state of dimension 128. Then, after all 48 rows have been\n",
        "# fed through the recurrent layer, the output is fed into a dense layer of dim\n",
        "# 64. Finally, this output is fed into the last dense layer of dim 7 (softmax).\n",
        "\n",
        "# Input shape - 48 rows x 48 pixels in each row\n",
        "# Recurrent Layer - Hidden State dim 128, 48 time steps (one for each row)\n",
        "# Dense Layer 1 - 256 Neurons\n",
        "# Output layer - 7 Neurons (Softmax)\n",
        "\n",
        "# Relu activation after the dense layer\n",
        "\n",
        "rnn_model = Sequential([\n",
        "    SimpleRNN(128, input_shape=(48, 48), return_sequences=False),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "rnn_model.fit(X_train_rnn, y_train, epochs=30, batch_size=64, validation_data=(X_test_rnn, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_XoP8K2L_oN",
        "outputId": "9c8089a9-4432-4bcf-a088-dfed01502cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.2541 - loss: 1.8002 - val_accuracy: 0.2952 - val_loss: 1.7401\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3045 - loss: 1.7255 - val_accuracy: 0.3374 - val_loss: 1.6833\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3184 - loss: 1.6997 - val_accuracy: 0.3376 - val_loss: 1.6684\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3306 - loss: 1.6739 - val_accuracy: 0.3431 - val_loss: 1.6580\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3378 - loss: 1.6634 - val_accuracy: 0.3419 - val_loss: 1.6553\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3375 - loss: 1.6604 - val_accuracy: 0.3390 - val_loss: 1.6571\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3546 - loss: 1.6460 - val_accuracy: 0.3502 - val_loss: 1.6650\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3523 - loss: 1.6345 - val_accuracy: 0.3647 - val_loss: 1.6190\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3561 - loss: 1.6345 - val_accuracy: 0.3357 - val_loss: 1.6700\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3598 - loss: 1.6250 - val_accuracy: 0.3608 - val_loss: 1.6182\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3542 - loss: 1.6256 - val_accuracy: 0.3470 - val_loss: 1.6535\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3672 - loss: 1.6092 - val_accuracy: 0.3508 - val_loss: 1.6422\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3610 - loss: 1.6179 - val_accuracy: 0.3543 - val_loss: 1.6386\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3741 - loss: 1.5977 - val_accuracy: 0.3671 - val_loss: 1.6353\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3614 - loss: 1.6170 - val_accuracy: 0.3739 - val_loss: 1.6129\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3347 - loss: 1.6646 - val_accuracy: 0.3661 - val_loss: 1.6370\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3711 - loss: 1.5976 - val_accuracy: 0.3682 - val_loss: 1.6006\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3763 - loss: 1.5783 - val_accuracy: 0.3812 - val_loss: 1.5859\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3710 - loss: 1.5914 - val_accuracy: 0.3224 - val_loss: 1.6920\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3578 - loss: 1.6191 - val_accuracy: 0.3773 - val_loss: 1.5956\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3787 - loss: 1.5790 - val_accuracy: 0.3709 - val_loss: 1.6024\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3870 - loss: 1.5659 - val_accuracy: 0.3734 - val_loss: 1.5909\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3750 - loss: 1.5843 - val_accuracy: 0.2558 - val_loss: 1.7993\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2743 - loss: 1.7702 - val_accuracy: 0.2792 - val_loss: 1.7813\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2943 - loss: 1.7405 - val_accuracy: 0.2981 - val_loss: 1.7272\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3061 - loss: 1.7172 - val_accuracy: 0.3069 - val_loss: 1.7244\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2966 - loss: 1.7266 - val_accuracy: 0.3189 - val_loss: 1.7035\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3109 - loss: 1.7065 - val_accuracy: 0.3108 - val_loss: 1.7128\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3179 - loss: 1.6967 - val_accuracy: 0.3263 - val_loss: 1.6768\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3255 - loss: 1.6803 - val_accuracy: 0.3278 - val_loss: 1.6821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d1686eb850>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix\n"
      ],
      "metadata": {
        "id": "mA7GmMLCMlPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The Standard Confusion Matrix\n",
        "\"\"\"\n",
        "def get_max_idx(arr):\n",
        "  cmax = 0\n",
        "  for i in range(len(arr)):\n",
        "    if arr[i] > arr[cmax]:\n",
        "      cmax = i\n",
        "  return cmax\n",
        "\n",
        "def create_cmatrix(predictions, labels):\n",
        "  cmatrix = []\n",
        "  for i in range(7):\n",
        "    r = []\n",
        "    for j in range(7):\n",
        "      r.append(0)\n",
        "    cmatrix.append(r)\n",
        "\n",
        "  for entry in range(len(predictions)):\n",
        "    predicted = get_max_idx(predictions[entry])\n",
        "    actual = get_max_idx(labels[entry])\n",
        "    cmatrix[actual][predicted] += 1\n",
        "  return cmatrix\n",
        "\n",
        "def display_cmatrix(cmatrix):\n",
        "  print(\"\\t\\tPREDICTED\\t\\t\")\n",
        "  print(\"['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\")\n",
        "  print(\"-----------------\")\n",
        "  print(\"A |\" + str(cmatrix[0]) + \"| angry\")\n",
        "  print(\"C |\" + str(cmatrix[1]) + \"| disgust\")\n",
        "  print(\"T |\" + str(cmatrix[2]) + \"| fear\")\n",
        "  print(\"U |\" + str(cmatrix[3]) + \"| happy\")\n",
        "  print(\"A |\" + str(cmatrix[4]) + \"| neutral\")\n",
        "  print(\"L |\" + str(cmatrix[5]) + \"| sad\")\n",
        "  print(\"  |\" + str(cmatrix[6]) + \"| suprise\")\n",
        "\n",
        "\n",
        "mlp_predictions = mlp_model.predict(X_test)\n",
        "rnn_predictions = rnn_model.predict(X_test)\n",
        "\n",
        "mlp_cmatrix = create_cmatrix(predictions=mlp_predictions, labels=y_test)\n",
        "rnn_cmatrix = create_cmatrix(predictions=rnn_predictions, labels=y_test)\n",
        "\n",
        "display_cmatrix(mlp_cmatrix)\n",
        "display_cmatrix(rnn_cmatrix)\n",
        "\n",
        "print(mlp_cmatrix)\n",
        "print(rnn_cmatrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okf09wQFfcg_",
        "outputId": "d1fcbec8-a946-4d8c-d082-e55279726199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\t\tPREDICTED\t\t\n",
            "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "-----------------\n",
            "A |[218, 2, 110, 202, 256, 109, 61]| angry\n",
            "C |[31, 2, 17, 19, 30, 9, 3]| disgust\n",
            "T |[113, 0, 187, 167, 330, 129, 98]| fear\n",
            "U |[129, 0, 87, 1095, 314, 92, 57]| happy\n",
            "A |[78, 0, 72, 219, 692, 131, 41]| neutral\n",
            "L |[135, 1, 152, 234, 417, 261, 47]| sad\n",
            "  |[36, 2, 97, 98, 190, 28, 380]| suprise\n",
            "\t\tPREDICTED\t\t\n",
            "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "-----------------\n",
            "A |[0, 0, 65, 346, 241, 173, 133]| angry\n",
            "C |[0, 0, 9, 49, 24, 7, 22]| disgust\n",
            "T |[0, 0, 91, 303, 262, 148, 220]| fear\n",
            "U |[1, 0, 58, 1161, 298, 139, 117]| happy\n",
            "A |[0, 0, 83, 390, 403, 193, 164]| neutral\n",
            "L |[2, 0, 78, 392, 380, 259, 136]| sad\n",
            "  |[0, 0, 63, 154, 113, 62, 439]| suprise\n",
            "[[218, 2, 110, 202, 256, 109, 61], [31, 2, 17, 19, 30, 9, 3], [113, 0, 187, 167, 330, 129, 98], [129, 0, 87, 1095, 314, 92, 57], [78, 0, 72, 219, 692, 131, 41], [135, 1, 152, 234, 417, 261, 47], [36, 2, 97, 98, 190, 28, 380]]\n",
            "[[0, 0, 65, 346, 241, 173, 133], [0, 0, 9, 49, 24, 7, 22], [0, 0, 91, 303, 262, 148, 220], [1, 0, 58, 1161, 298, 139, 117], [0, 0, 83, 390, 403, 193, 164], [2, 0, 78, 392, 380, 259, 136], [0, 0, 63, 154, 113, 62, 439]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Tests for Comparison with LLM**"
      ],
      "metadata": {
        "id": "zF-PVBz83NeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Very first block of code need to be ran for this\n",
        "files_to_test = {\n",
        "    \"angry\": [\"PublicTest_26506006.jpg\", \"PrivateTest_18347688.jpg\", \"PrivateTest_22419133.jpg\", \"PublicTest_47452496.jpg\", \"PublicTest_47804687.jpg\"],\n",
        "    \"disgust\": [\"PrivateTest_60490187.jpg\", \"PublicTest_99162116.jpg\", \"PublicTest_75786377.jpg\", \"PrivateTest_30523217.jpg\", \"PrivateTest_92933222.jpg\"],\n",
        "    \"fear\": [\"PrivateTest_7261364.jpg\", \"PublicTest_89131102.jpg\", \"PrivateTest_31388255.jpg\", \"PublicTest_4506555.jpg\", \"PublicTest_54050404.jpg\"],\n",
        "    \"happy\": [\"PublicTest_83097075.jpg\", \"PrivateTest_4014756.jpg\", \"PublicTest_46945921.jpg\", \"PublicTest_15499192.jpg\", \"PublicTest_40541412.jpg\"],\n",
        "    \"neutral\": [\"PublicTest_10726845.jpg\", \"PublicTest_78125500.jpg\", \"PublicTest_65439988.jpg\", \"PublicTest_80317721.jpg\", \"PublicTest_67747988.jpg\"],\n",
        "    \"sad\": [\"PrivateTest_60103853.jpg\", \"PrivateTest_86106478.jpg\", \"PublicTest_38013120.jpg\", \"PublicTest_69378300.jpg\", \"PrivateTest_55277524.jpg\"],\n",
        "    \"surprise\": [\"PrivateTest_25288007.jpg\", \"PrivateTest_51290776.jpg\", \"PublicTest_49049109.jpg\", \"PublicTest_64740817.jpg\", \"PublicTest_64532931.jpg\"]\n",
        "}\n",
        "\n",
        "\n",
        "def load_samples_for_test(root_dir, samples, target_size=(48, 48)):\n",
        "    X, y = [], []\n",
        "    for class_folder in os.listdir(root_dir):\n",
        "        class_path = os.path.join(root_dir, class_folder)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "        label = class_folder.lower()\n",
        "        # look through file through the samples instead of through each class folder\n",
        "        for file in samples[class_path.split(\"/\")[-1]]:\n",
        "            img_path = os.path.join(class_path, file)\n",
        "            try:\n",
        "                img = Image.open(img_path).convert(\"L\").resize(target_size)\n",
        "                X.append(np.array(img))\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {img_path}: {e}\")\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_sample_test, y_sample_test = load_samples_for_test(test_dir, files_to_test)\n",
        "y_sample_test = to_categorical(label_encoder.transform(y_sample_test))\n",
        "print(f\"Samples: {X_sample_test.shape}, {y_sample_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUjsmuNGx2Ii",
        "outputId": "d1380fc0-dc2f-40db-b43b-1a2e25fca56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: (35, 48, 48), (35, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_sample_predictions = mlp_model.predict(X_sample_test)\n",
        "rnn_sample_predictions = rnn_model.predict(X_sample_test)\n",
        "\n",
        "mlp_sample_cmatrix = create_cmatrix(predictions=mlp_sample_predictions, labels=y_sample_test)\n",
        "rnn_sample_cmatrix = create_cmatrix(predictions=rnn_sample_predictions, labels=y_sample_test)\n",
        "\n",
        "display_cmatrix(mlp_sample_cmatrix)\n",
        "display_cmatrix(rnn_sample_cmatrix)\n",
        "print(\"-\"*30)\n",
        "print(\"MLP SAMPLE MATRIX\")\n",
        "print(mlp_sample_cmatrix)\n",
        "print(\"-\"*30)\n",
        "print(\"RNN SAMPLE MATRIX\")\n",
        "print(rnn_sample_cmatrix)\n",
        "print(\"-\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMamiuhn3CPP",
        "outputId": "d4d9d30f-8981-4541-f759-a0d4f5068da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\t\tPREDICTED\t\t\n",
            "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "-----------------\n",
            "A |[0, 0, 1, 0, 1, 0, 3]| angry\n",
            "C |[0, 0, 3, 0, 1, 0, 1]| disgust\n",
            "T |[0, 0, 1, 0, 0, 0, 4]| fear\n",
            "U |[0, 0, 0, 1, 1, 0, 3]| happy\n",
            "A |[0, 0, 0, 0, 1, 1, 3]| neutral\n",
            "L |[0, 0, 2, 2, 1, 0, 0]| sad\n",
            "  |[0, 0, 1, 0, 0, 0, 4]| suprise\n",
            "\t\tPREDICTED\t\t\n",
            "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
            "-----------------\n",
            "A |[0, 0, 0, 2, 0, 0, 3]| angry\n",
            "C |[0, 0, 1, 2, 1, 0, 1]| disgust\n",
            "T |[0, 0, 0, 4, 0, 0, 1]| fear\n",
            "U |[0, 0, 0, 4, 0, 0, 1]| happy\n",
            "A |[0, 0, 1, 3, 0, 0, 1]| neutral\n",
            "L |[0, 0, 0, 4, 1, 0, 0]| sad\n",
            "  |[0, 0, 2, 2, 0, 0, 1]| suprise\n",
            "------------------------------\n",
            "MLP SAMPLE MATRIX\n",
            "[[0, 0, 1, 0, 1, 0, 3], [0, 0, 3, 0, 1, 0, 1], [0, 0, 1, 0, 0, 0, 4], [0, 0, 0, 1, 1, 0, 3], [0, 0, 0, 0, 1, 1, 3], [0, 0, 2, 2, 1, 0, 0], [0, 0, 1, 0, 0, 0, 4]]\n",
            "------------------------------\n",
            "RNN SAMPLE MATRIX\n",
            "[[0, 0, 0, 2, 0, 0, 3], [0, 0, 1, 2, 1, 0, 1], [0, 0, 0, 4, 0, 0, 1], [0, 0, 0, 4, 0, 0, 1], [0, 0, 1, 3, 0, 0, 1], [0, 0, 0, 4, 1, 0, 0], [0, 0, 2, 2, 0, 0, 1]]\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}